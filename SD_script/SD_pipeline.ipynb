{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/SSD_mmlab/martina.dangelo/fake-image-detectors/myvenv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 4080 SUPER\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionXLPipeline\n",
    "import torch\n",
    "from accelerate import infer_auto_device_map\n",
    "import random\n",
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:02<00:00,  2.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# Carica il modello dalla piattaforma Hugging Face\n",
    "model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "\n",
    "# Configura la pipeline\n",
    "pipeline = StableDiffusionXLPipeline.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch.float16, \n",
    "    use_safetensors=True,  # Per performance migliori\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Seed:  330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  6.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# Prompt di esempio\n",
    "prompt = \"A futuristic cityscape illuminated by neon lights at sunset, with towering skyscrapers made of glass and steel, flying vehicles in the sky, a bustling street market with diverse people, vibrant colors, hyper-realistic details, cinematic lighting, intricate reflections on the buildings, soft pink and orange hues in the sky, ultra-high definition, photorealistic, 16k resolution.\"\n",
    "negative = \"blurry, low quality, pixelated, out of focus, overexposed, underexposed, cartoonish, 2D art, poorly detailed, text artifacts, watermark, deformed buildings, unrealistic proportions, grainy textures, flat colors, monochrome, color bleeding, low resolution, bad composition.\"\n",
    "\n",
    "num_inference_steps=50\n",
    "guidance_scale=7.5\n",
    "\n",
    "height = 1024  # Altezza in pixel\n",
    "width = 1024  # Larghezza in pixel\n",
    "\n",
    "# random seed\n",
    "seed = random.randint(1,1000)\n",
    "print(\"Using Seed: \",seed)\n",
    "generator = torch.Generator(device=\"cpu\").manual_seed(seed)\n",
    "\n",
    "# Generazione dell'immagine\n",
    "image = pipeline(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=negative,                   # Prompt negativo\n",
    "    height=height,\n",
    "    width=width,\n",
    "    num_inference_steps=num_inference_steps,    # Passi di inferenza (maggiore = più dettagli)\n",
    "    guidance_scale= guidance_scale,              # Peso per il prompt (maggiore = risultati più aderenti)\n",
    "    generator=generator\n",
    ").images[0]\n",
    "\n",
    "# Salva l'immagine generata\n",
    "image.save(f\"imgs/{str(seed)}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images:  4\n",
      "1/16\n",
      "2/16\n",
      "3/16\n",
      "4/16\n",
      "5/16\n",
      "6/16\n",
      "7/16\n",
      "8/16\n",
      "9/16\n",
      "10/16\n",
      "11/16\n",
      "12/16\n",
      "13/16\n",
      "14/16\n",
      "15/16\n",
      "16/16\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "PATCH_SIZE = 1024\n",
    "DEBUG = False\n",
    "WRITE = True\n",
    "FOLDER_PATH = \"imgs/\"\n",
    "OUTPUT_FOLDER_PATH = \"cropped_imgs/\"\n",
    "FILE_FORMAT = (\".png\", \".jpg\")\n",
    "\n",
    "\n",
    "# Recupera lista img da FOLDER_PATH\n",
    "images = [os.path.join(FOLDER_PATH, file) for file in os.listdir(FOLDER_PATH) if file.lower().endswith(FILE_FORMAT)]\n",
    "\n",
    "print(\"Total images: \",len(images))\n",
    "os.makedirs(OUTPUT_FOLDER_PATH, exist_ok=True)  # Crea la directory se non esiste\n",
    "\n",
    "PROCESSED_IMG = len(images) \n",
    "PATCH_FOR_IMG = 4\n",
    "\n",
    "# Process x images\n",
    "random_image_list = random.sample(images, PROCESSED_IMG)\n",
    "\n",
    "counter_tot = PROCESSED_IMG * PATCH_FOR_IMG\n",
    "current_counter = 1\n",
    "for file_name in random_image_list:\n",
    "    img = cv2.imread(file_name)\n",
    "\n",
    "    max_y = img.shape[0]-PATCH_SIZE\n",
    "    max_x = img.shape[1]-PATCH_SIZE\n",
    "\n",
    "    file_name_no_ext, ext = os.path.splitext(os.path.basename(file_name))\n",
    "\n",
    "    # Crop x patches\n",
    "    for patch_number in range(0, PATCH_FOR_IMG):\n",
    "        top_left = (random.randint(0, max_x), random.randint(0, max_y))\n",
    "        bot_right = (top_left[0]+PATCH_SIZE, top_left[1]+PATCH_SIZE)        \n",
    "\n",
    "        cropped_image = img[top_left[1]:top_left[1]+PATCH_SIZE, top_left[0]:top_left[0]+1024]\n",
    "\n",
    "        if(DEBUG):\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            cropped_image_rgb = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            cv2.rectangle(img_rgb, top_left, bot_right, (255, 0, 0), 20)  # Drawing in RGB\n",
    "\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(img_rgb)\n",
    "            plt.title(\"Original Image\")\n",
    "            plt.axis(\"off\")\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(cropped_image_rgb)\n",
    "            plt.title(\"Cropped Patch\")\n",
    "            plt.axis(\"off\")\n",
    "            plt.show()\n",
    "\n",
    "        save_name = OUTPUT_FOLDER_PATH + \"/\" + file_name_no_ext + \"-\" + str(patch_number+1) + \".png\"\n",
    "\n",
    "        if WRITE:\n",
    "            cv2.imwrite(str(save_name), cropped_image)\n",
    "\n",
    "        print(str(current_counter) + \"/\" + str(counter_tot))\n",
    "        current_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
