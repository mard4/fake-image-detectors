{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Number of GPUs: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 4080 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "print(\"Current device:\", torch.cuda.current_device())\n",
    "print(\"Device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Seed:  1049023134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████| 7/7 [00:02<00:00,  2.93it/s]\n"
     ]
    }
   ],
   "source": [
    "from diffusers import StableDiffusionXLPipeline\n",
    "import torch\n",
    "from accelerate import infer_auto_device_map\n",
    "import random\n",
    "\n",
    "# Carica il modello dalla piattaforma Hugging Face\n",
    "model_id = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "\n",
    "\n",
    "# Configura la pipeline\n",
    "pipeline = StableDiffusionXLPipeline.from_pretrained(\n",
    "    model_id, \n",
    "    torch_dtype=torch.float16, \n",
    "    use_safetensors=True,  # Per performance migliori\n",
    ").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Seed:  4285379855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:08<00:00,  6.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Prompt di esempio\n",
    "prompt = \"A futuristic cityscape illuminated by neon lights at sunset, with towering skyscrapers made of glass and steel, flying vehicles in the sky, a bustling street market with diverse people, vibrant colors, hyper-realistic details, cinematic lighting, intricate reflections on the buildings, soft pink and orange hues in the sky, ultra-high definition, photorealistic, 16k resolution.\"\n",
    "negative = \"blurry, low quality, pixelated, out of focus, overexposed, underexposed, cartoonish, 2D art, poorly detailed, text artifacts, watermark, deformed buildings, unrealistic proportions, grainy textures, flat colors, monochrome, color bleeding, low resolution, bad composition.\"\n",
    "\n",
    "num_inference_steps=50\n",
    "guidance_scale=7.5\n",
    "\n",
    "height = 1024  # Altezza in pixel\n",
    "width = 1024  # Larghezza in pixel\n",
    "\n",
    "# random seed\n",
    "seed = random.randint(8, 2**32-1)\n",
    "print(\"Using Seed: \",seed)\n",
    "generator = torch.Generator(device=\"cpu\").manual_seed(seed)\n",
    "\n",
    "# Generazione dell'immagine\n",
    "image = pipeline(\n",
    "    prompt=prompt,\n",
    "    negative_prompt=negative,                   # Prompt negativo\n",
    "    height=height,\n",
    "    width=width,\n",
    "    num_inference_steps=num_inference_steps,    # Passi di inferenza (maggiore = più dettagli)\n",
    "    guidance_scale= guidance_scale,              # Peso per il prompt (maggiore = risultati più aderenti)\n",
    "    generator=generator\n",
    ").images[0]\n",
    "\n",
    "# Salva l'immagine generata\n",
    "image.save(\"output_image.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To simulate such forms of image laundering and to avoid polarization, we follow the procedure used in the IEEE VIP Cup [13]. For each image of the test, a crop with random (large) size and position is selected, resized to 200 × 200 pixels, and compressed using a random JPEG quality factor from 65 to 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
