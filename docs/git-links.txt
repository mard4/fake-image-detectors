ATTACK

[When Synthetic Traces Hide Real Content: Analysis of Stable Diffusion Image Laundering] | https://github.com/polimi-ispl/synthetic-image-detection
[Exploring the Adversarial Robustness of CLIP for AI-generated Image Detection] | ---
[Adversarial image detection in deep neural networks] | ---
[Evading Deepfake-Image Detectors with White- and Black-Box Attacks] | ---
[Adversarial mimicry attacks against image splicing forensics: An approach for jointly hiding manipulations and creating false detections] | ---

DETECT

[Exposing GAN-Generated Profile Photos from Compact Embeddings] | ---
[PERSPECTIVE (IN) CONSISTENCY OF PAINT BY TEXT] | ---
[LIGHTING (IN) CONSISTENCY OF PAINT BY TEXT] | ---
[Raising the Bar of AI-generated Image Detection with CLIP] | https://github.com/grip-unina/ClipBased-SyntheticImageDetection
[ON THE DETECTION OF SYNTHETIC IMAGES GENERATED BY DIFFUSION MODELS] | https://github.com/grip-unina/DMimageDetection
[Finding AI-Generated Faces in the Wild] | ---

MODELS
[SDXL] https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/tree/main
[SDXL-Turbo] https://huggingface.co/stabilityai/sdxl-turbo/tree/main



[STABLE-DIFFUSION][https://github.com/CompVis/stable-diffusion]

# EXPERIMENTAL
[Attack with GradCam] https://github.com/wkim97/ada?tab=readme-ov-file
