# fake-image-detectors


Exploring the Adversarial Robustness of AI-generated
Image Detectors
The students working on this project will:

- Work on a large and diverse dataset of images generated by the MMLAB group with several generative techniques
- Evaluate the Adversarial Robustness of a Fake Image Detectors under different attacks

● Get familiar with deepfake detection State-of-the-Art (SoA)
- CLIP-aided fake image detection
- ResNet50 fake image detection
- Robust Artifacts for Fake Image Detection
- Exposing gan-generated profile photos from compact embeddings
- Lighting (in) consistency of paint by text
- Perspective (in) consistency of paint by text

● Get familiar with multimedia forensics adversarial attacks SoA
- Mimicry attack (Boato2023)
- Carlini Farid
- Carrara
- Verdoliva
- Stable Diffusion Laundering

● Challenge modern fake image detectors by using the above mentioned adversarial
techniques and develop solution robust to these latter.

# Utils

source myvenv/bin/activate